A litany of tests were ran along with permutations of convolutional and pooling layers. 
This increased processing time lowering optimization which is not cost effect and worsens with bigger data sets.
Removing the dropout layer after the hidden layers increased the accuracy significantly
Decreasing the pooling size also led to an increase in the accuracy
I inevitablely used 2 hidden layers of 128 nodes and the final accuracy of 0.96.